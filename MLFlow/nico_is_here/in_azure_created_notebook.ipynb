{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Utilisation dans Azure d'un dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# le data set est d'abord créé dans le menu Asset / Data / Create\n",
        "# Actifs multimedias / Données / Créer (en français)\n",
        "\n",
        "ml_client = MLClient.from_config(credential=DefaultAzureCredential())\n",
        "data_asset = ml_client.data.get(\"titanic_data\", version=\"1\")\n",
        "\n",
        "df_original = pd.read_csv(data_asset.path)\n",
        "df_original.head()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'null/Users/ncassonet.ext'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnull/Users/ncassonet.ext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'null/Users/ncassonet.ext'"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1745325809882
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nouvelle version du dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "df_cleaned = df_original.drop(columns=[\"Cabin\"], errors=\"ignore\")\n",
        "\n",
        "# Sauvegarde locale du nouveau CSV\n",
        "cleaned_path = \"titanic_data_cleaned.csv\"\n",
        "df_cleaned.to_csv(cleaned_path, index=False)\n",
        "\n",
        "new_version = ml_client.data.get(\"titanic_data\", version=\"2\")\n",
        "if new_version :\n",
        "    print(f\"titanic_data version 2 allready exists\")\n",
        "\n",
        "else : \n",
        "    # Création de la nouvelle version du Data Asset (v2)\n",
        "    new_data_asset = Data(\n",
        "        path=cleaned_path,\n",
        "        type=AssetTypes.URI_FILE,\n",
        "        name=\"titanic_data\",  # même nom\n",
        "        version=\"2\",              # nouvelle version\n",
        "        description=\"Version nettoyée sans la colonne Cabin\"\n",
        "    )\n",
        "\n",
        "    ml_client.data.create_or_update(new_data_asset)\n",
        "    print(f\"titanic_data version 2 created\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "titanic_data version 2 allready exists\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1745316562426
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entraîner un modèle et consigner les résultats obtenus avec MLflow dans Azure ML"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "# ajouté pour enregistrer le modèle\n",
        "from mlflow import register_model\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Connexion + chargement du dataset v2\n",
        "ml_client = MLClient.from_config(credential=DefaultAzureCredential())\n",
        "data_asset = ml_client.data.get(name=\"titanic_data_set\", version=\"2\")\n",
        "df = pd.read_csv(data_asset.path)\n",
        "\n",
        "# Préparation des données (exemple simple)\n",
        "df = df.dropna()\n",
        "X = df.drop(columns=[\"Survived\"])\n",
        "y = df[\"Survived\"]\n",
        "\n",
        "# Dummy encoding si besoin (ex: pour les colonnes catégorielles)\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "# Split train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Démarrer un run MLflow\n",
        "with mlflow.start_run()as running_mlflow :\n",
        "    log_reg_titanic_model = LogisticRegression(max_iter=200)\n",
        "    log_reg_titanic_model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = log_reg_titanic_model.predict(X_test)\n",
        "    y_proba = log_reg_titanic_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Métriques\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "    # Log avec MLflow\n",
        "    mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "    mlflow.log_metric(\"precision\", precision)\n",
        "    mlflow.log_metric(\"recall\", recall)\n",
        "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
        "\n",
        "    mlflow.sklearn.log_model(log_reg_titanic_model, \"model\")\n",
        "\n",
        "    print(f\"✅ Modèle loggé avec MLflow - F1: {f1:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, AUC: {roc_auc:.3f}\")\n",
        "\n",
        "    # Sauvegarde de l'ID du run\n",
        "    run_id = running_mlflow.info.run_id\n",
        "    print(f\"Modèle loggé dans le run ID: {run_id}\")\n",
        "\n",
        "    registered_model = mlflow.register_model(\n",
        "        model_uri=f\"runs:/{run_id}/model\",  # lien vers le modèle loggé\n",
        "        name=\"log_reg_titanic_model\"        # nom du modèle dans Azure ML\n",
        "    )\n",
        "\n",
        "    print(f\"✅ Modèle enregistré dans Azure ML : {registered_model.name}, version : {registered_model.version}\")\n",
        "  "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azureml/mlflow/_protos/aml_service_pb2.py:10: UserWarning: google.protobuf.service module is deprecated. RPC implementations should provide code generator plugins which generate code specific to the RPC implementation. service.py will be removed in Jan 2025\n  from google.protobuf import service as _service\n/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n2025/04/09 14:14:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1744199754135
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "client = MlflowClient()\n",
        "client.update_registered_model(\n",
        "    name=\"log_reg_titanic_model\",\n",
        "    description=\"Modèle sklearn pour prédire la survie sur Titanic\"\n",
        ")\n",
        "\n",
        "# ajout de description, tags\n",
        "client.set_registered_model_tag(\"log_reg_titanic_model\", \"framework\", \"sklearn\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1744199754611
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "fr"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}