{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77742e0f",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afdf2b72",
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install --force-reinstall --no-cache-dir numpy pandas\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import joblib\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from xgboost import XGBRegressor\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3ecd0b3",
      "metadata": {
        "gather": {
          "logged": 1744810443341
        }
      },
      "outputs": [],
      "source": [
        "def load_data(filepath, sep=';', encoding='utf-8'):\n",
        "    \"\"\"Charge les données avec gestion des erreurs améliorée\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(filepath, sep=sep, engine='python', quoting=3, \n",
        "                         on_bad_lines='skip', encoding=encoding)\n",
        "        print(f\"Chargement réussi: {df.shape[0]} lignes et {df.shape[1]} colonnes\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur lors du chargement: {e}\")\n",
        "        try:\n",
        "            # Alternative avec CSV standard\n",
        "            df = pd.read_csv(filepath, sep=sep, encoding=encoding)\n",
        "            print(f\"Chargement alternatif réussi: {df.shape[0]} lignes et {df.shape[1]} colonnes\")\n",
        "            return df\n",
        "        except Exception as e2:\n",
        "            print(f\"Échec du chargement alternatif: {e2}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "df = load_data('fusionV3.csv')\n",
        "df_clean = df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de39fe7f",
      "metadata": {},
      "source": [
        "Delete colonnes inutiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b28df65e",
      "metadata": {
        "gather": {
          "logged": 1744810443368
        }
      },
      "outputs": [],
      "source": [
        "# Liste des colonnes à supprimer\n",
        "colonnes_a_supprimer = [\n",
        "    \"titre_jpbox\"\n",
        "]\n",
        "\n",
        "# Supprimer uniquement les colonnes qui existent dans le dataframe\n",
        "colonnes_existantes = [col for col in colonnes_a_supprimer if col in df_clean.columns]\n",
        "\n",
        "# Supprimer les colonnes\n",
        "df_clean = df_clean.drop(columns=colonnes_existantes)\n",
        "\n",
        "# Afficher un message indiquant quelles colonnes ont été supprimées\n",
        "print(f\"{len(colonnes_existantes)} colonnes ont été supprimées sur {len(colonnes_a_supprimer)} demandées.\")\n",
        "print(f\"Colonnes supprimées: {colonnes_existantes}\")\n",
        "print(f\"Colonnes restantes: {df_clean.columns.tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "785009b4",
      "metadata": {},
      "source": [
        "Création du jeu de données de test "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f647d62b",
      "metadata": {
        "gather": {
          "logged": 1744810443395
        }
      },
      "outputs": [],
      "source": [
        "films_test = [\n",
        "    \"Zion\", \n",
        "    \"Dog Man\", \n",
        "    \"Doux Jésus\", \n",
        "    \"Mikado\", \n",
        "    \"One of Them Days\", \n",
        "    \"Cassandre\", \n",
        "    \"Le Routard\",\n",
        "    \"Banger\",\n",
        "    \"Minecraft, Le Film\"\n",
        "]\n",
        "\n",
        "films_present = df_clean[df['titre_allocine'].isin(films_test)]\n",
        "\n",
        "print(films_present)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "128bc2b2",
      "metadata": {
        "gather": {
          "logged": 1744810443422
        }
      },
      "outputs": [],
      "source": [
        "# D'abord, vérifions les colonnes disponibles\n",
        "print(\"Colonnes disponibles:\", df_clean.columns.tolist())\n",
        "\n",
        "# Trouvons une colonne qui contient les titres des films\n",
        "# Examinons les premières lignes pour voir où sont stockés les titres\n",
        "print(df_clean.head(3))\n",
        "\n",
        "# En se basant sur les données partagées, les titres peuvent être dans d'autres colonnes\n",
        "# Essayons de trouver des correspondances dans les colonnes synopsis_x ou synopsis_y\n",
        "# qui pourraient contenir des descriptions avec les titres\n",
        "\n",
        "# Option 1: Utiliser la colonne 'synopsis_x' ou 'synopsis_y' pour identifier les films\n",
        "mask_films_test = False\n",
        "for film in films_test:\n",
        "    if 'synopsis_x' in df_clean.columns:\n",
        "        mask_films_test = mask_films_test | df_clean['synopsis_x'].str.contains(film, case=False, na=False)\n",
        "    if 'synopsis_y' in df_clean.columns:\n",
        "        mask_films_test = mask_films_test | df_clean['synopsis_y'].str.contains(film, case=False, na=False)\n",
        "\n",
        "# Option 2: Si vous avez identifié la bonne colonne pour les titres de films\n",
        "# (peut-être en examinant les colonnes disponibles), utilisez celle-ci:\n",
        "# Exemple si les titres sont dans une colonne appelée 'titre' ou autre chose:\n",
        "titre_column = None\n",
        "potential_title_columns = ['titre', 'titre_jpbox', 'film_title', 'name', 'title']\n",
        "for col in potential_title_columns:\n",
        "    if col in df_clean.columns:\n",
        "        titre_column = col\n",
        "        print(f\"Colonne de titre trouvée: {col}\")\n",
        "        break\n",
        "\n",
        "# Si nous avons trouvé une colonne de titre\n",
        "if titre_column:\n",
        "    mask_films_test = df_clean[titre_column].isin(films_test)\n",
        "    print(f\"Films trouvés avec {titre_column}: {df_clean[mask_films_test].shape[0]}\")\n",
        "\n",
        "# Option 3: Utiliser simplement les films d'avril 2025\n",
        "print(\"Utilisation des films d'avril 2025 comme jeu de test...\")\n",
        "mask_avril_2025 = df_clean['date_sortie_france'].str.contains('04/2025', na=False)\n",
        "print(f\"Films d'avril 2025 trouvés: {df_clean[mask_avril_2025].shape[0]}\")\n",
        "\n",
        "# Créer le dataframe de test avec les films d'avril 2025\n",
        "df_test = df_clean[mask_avril_2025].copy()\n",
        "print(f\"Nombre de films extraits pour le test: {len(df_test)}\")\n",
        "\n",
        "# Sauvegarder les valeurs réelles pour l'évaluation future (si disponibles)\n",
        "if 'box_office_demarrage' in df_test.columns:\n",
        "    box_office_reels = df_test['box_office_demarrage'].copy()\n",
        "    print(\"Valeurs box office sauvegardées pour évaluation.\")\n",
        "else:\n",
        "    # Créer une série vide si la colonne n'existe pas\n",
        "    box_office_reels = pd.Series([None] * len(df_test), index=df_test.index)\n",
        "    print(\"ATTENTION: Colonne box_office_demarrage non trouvée.\")\n",
        "\n",
        "# Mettre à NULL la cible dans le dataframe de test (si elle existe)\n",
        "if 'box_office_demarrage' in df_test.columns:\n",
        "    df_test['box_office_demarrage'] = None\n",
        "\n",
        "# Retirer ces films du dataframe principal\n",
        "df_clean = df_clean[~mask_avril_2025]\n",
        "print(f\"Nombre de films restants dans le dataset principal: {len(df_clean)}\")\n",
        "\n",
        "# Afficher les titres des films de test\n",
        "print(\"\\nFilms extraits pour le test:\")\n",
        "for i, (_, film) in enumerate(df_test.iterrows()):\n",
        "    # Utiliser les informations disponibles\n",
        "    film_info = []\n",
        "    if 'synopsis_x' in film and isinstance(film['synopsis_x'], str) and len(film['synopsis_x']) > 10:\n",
        "        film_info.append(film['synopsis_x'][:50] + \"...\")\n",
        "    if 'genres' in film:\n",
        "        film_info.append(f\"Genre: {film['genres']}\")\n",
        "    if 'date_sortie_france' in film:\n",
        "        film_info.append(f\"Sortie: {film['date_sortie_france']}\")\n",
        "    \n",
        "    box_office = box_office_reels.iloc[i] if i < len(box_office_reels) else None\n",
        "    box_office_text = f\"Box office: {box_office}\" if box_office is not None else \"Box office: Non disponible\"\n",
        "    \n",
        "    print(f\"- Film {i+1}: {' | '.join(film_info)}\")\n",
        "    print(f\"  {box_office_text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47d5f809",
      "metadata": {},
      "source": [
        "Nettoyage des valeurs monétaire"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8808c581",
      "metadata": {
        "gather": {
          "logged": 1744810443455
        }
      },
      "outputs": [],
      "source": [
        "def clean_monetary_value(value):\n",
        "    \"\"\"Nettoie et convertit les valeurs monétaires avec gestion améliorée des erreurs\"\"\"\n",
        "    # Dictionnaire des taux de conversion approximatifs\n",
        "    currency_rates = {\n",
        "        '€': 1.1,  # Euro vers Dollar\n",
        "        '£': 1.25, # Livre vers Dollar\n",
        "        '¥': 0.0068, # Yen vers Dollar\n",
        "        'CA$': 0.73, # Dollar canadien vers Dollar américain\n",
        "        'A$': 0.65  # Dollar australien vers Dollar américain\n",
        "    }\n",
        "    \n",
        "    if pd.isna(value) or value in ['Non disponible', '?', '? $', '- $', '-', '', 'nan', '? €']:\n",
        "        return np.nan\n",
        "        \n",
        "    if isinstance(value, str):\n",
        "        # Vérifier si la chaîne est un titre de film ou un texte non pertinent\n",
        "        if len(value) > 20 and not any(c.isdigit() for c in value):\n",
        "            return np.nan\n",
        "            \n",
        "        # Détecter la devise et convertir en USD\n",
        "        for symbol, rate in currency_rates.items():\n",
        "            if symbol in value:\n",
        "                cleaned_value = value.replace(symbol, '').replace(' ', '').strip()\n",
        "                try:\n",
        "                    return float(cleaned_value.replace(',', '.')) * rate\n",
        "                except ValueError:\n",
        "                    continue\n",
        "                    \n",
        "        # Traitement standard pour les montants en dollars\n",
        "        cleaned_value = value.replace('$', '').replace(' ', '').replace(',', '.').strip()\n",
        "        \n",
        "        if cleaned_value == '' or cleaned_value == '-':\n",
        "            return np.nan\n",
        "            \n",
        "        try:\n",
        "            return float(cleaned_value)\n",
        "        except ValueError:\n",
        "            return np.nan\n",
        "            \n",
        "    return value\n",
        "\n",
        "\n",
        "\n",
        "# NETTOYAGE DES COLONNES MONÉTAIRES\n",
        "monetary_columns = ['budget', 'box_office_demarrage', 'trailer_views']\n",
        "\n",
        "for col in monetary_columns:\n",
        "    if col in df_test.columns:\n",
        "        print(f\"Nettoyage de la colonne {col}...\")\n",
        "        df_test[col] = df_test[col].apply(clean_monetary_value)\n",
        "\n",
        "if 'trailer_views' in df_test.columns:\n",
        "    # Nettoyage spécifique pour trailer_views\n",
        "    df_test['trailer_views_clean'] = df_test['trailer_views'].apply(\n",
        "        lambda x: float(str(x).replace('vues', '').replace(',', '').strip()) \n",
        "        if isinstance(x, str) and 'vues' in x else np.nan\n",
        "    )\n",
        "    \n",
        "    # Transformation logarithmique des vues\n",
        "    df_test['log_trailer_views'] = np.log1p(df_test['trailer_views_clean'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ad2a03d",
      "metadata": {
        "gather": {
          "logged": 1744810443484
        }
      },
      "outputs": [],
      "source": [
        "# TRAITEMENT DU JEU DE DONNEES DE TEST\n",
        "monetary_columns = ['budget', 'box_office_demarrage', 'trailer_views']\n",
        "\n",
        "for col in monetary_columns:\n",
        "    if col in df_test.columns:\n",
        "        print(f\"Nettoyage de la colonne {col}...\")\n",
        "        df_test[col] = df_test[col].apply(clean_monetary_value)\n",
        "\n",
        "if 'trailer_views' in df_test.columns:\n",
        "    # Nettoyage spécifique pour trailer_views\n",
        "    df_test['trailer_views_clean'] = df_test['trailer_views'].apply(\n",
        "        lambda x: float(str(x).replace('vues', '').replace(',', '').strip()) \n",
        "        if isinstance(x, str) and 'vues' in x else np.nan\n",
        "    )\n",
        "    \n",
        "    # Transformation logarithmique des vues\n",
        "    df_test['log_trailer_views'] = np.log1p(df_test['trailer_views_clean'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cd70df8",
      "metadata": {},
      "source": [
        "Nettoyage de la durée"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baf0ed2b",
      "metadata": {
        "gather": {
          "logged": 1744810443512
        }
      },
      "outputs": [],
      "source": [
        "def extract_duration_minutes(duration):\n",
        "    \"\"\"Extrait la durée en minutes à partir de différents formats\"\"\"\n",
        "    if pd.isna(duration):\n",
        "        return np.nan\n",
        "        \n",
        "    # Si c'est déjà un nombre, le retourner\n",
        "    if isinstance(duration, (int, float)):\n",
        "        return float(duration)\n",
        "        \n",
        "    # Convertir en string pour traiter\n",
        "    duration_str = str(duration)\n",
        "    \n",
        "    # Format '1h 32min' ou '1h32min' ou '1h32'\n",
        "    match = re.search(r'(\\d+)h\\s*(\\d*)', duration_str)\n",
        "    if match:\n",
        "        hours = int(match.group(1))\n",
        "        minutes = 0\n",
        "        if match.group(2):\n",
        "            minutes = int(match.group(2))\n",
        "        return hours * 60 + minutes\n",
        "    \n",
        "    # Format '92min' ou '92 min'\n",
        "    match = re.search(r'(\\d+)\\s*min', duration_str)\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    \n",
        "    # Format simple nombre (déjà en minutes)\n",
        "    try:\n",
        "        return float(duration_str)\n",
        "    except ValueError:\n",
        "        return np.nan\n",
        "    \n",
        "\n",
        "\n",
        "# TRAITEMENT DE LA DUREE\n",
        "if 'duration' in df_test.columns:\n",
        "    df_test['duree_minutes'] = df_test['duration'].apply(extract_duration_minutes)\n",
        "elif 'duree' in df_clean.columns:\n",
        "    df_clean['duree_minutes'] = df_clean['duree'].apply(extract_duration_minutes)\n",
        "\n",
        "# Création d'une colonne unique pour la durée\n",
        "if 'duree_minutes' in df_clean.columns:\n",
        "    df_clean['duree_film'] = df_clean['duree_minutes']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2627fb7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TRAITEMENT DU JEU DE DONNEES DE TEST\n",
        "if 'duration' in df_test.columns:\n",
        "    df_test['duree_minutes'] = df_test['duration'].apply(extract_duration_minutes)\n",
        "elif 'duree' in df_test.columns:\n",
        "    df_test['duree_minutes'] = df_test['duree'].apply(extract_duration_minutes)\n",
        "\n",
        "# Création d'une colonne unique pour la durée\n",
        "if 'duree_minutes' in df_test.columns:\n",
        "    df_test['duree_film'] = df_test['duree_minutes']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edb44317",
      "metadata": {},
      "source": [
        "Nettoyage des notes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8fe01cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_numeric_value(value):\n",
        "    \"\"\"Nettoie et convertit les valeurs numériques générales\"\"\"\n",
        "    if pd.isna(value) or value in ['Non disponible', '?', '-', '', 'nan']:\n",
        "        return np.nan\n",
        "        \n",
        "    if isinstance(value, str):\n",
        "        cleaned_value = value.replace(',', '.').strip()\n",
        "        \n",
        "        if cleaned_value == '' or cleaned_value == '-':\n",
        "            return np.nan\n",
        "            \n",
        "        try:\n",
        "            return float(cleaned_value)\n",
        "        except ValueError:\n",
        "            return np.nan\n",
        "            \n",
        "    return value\n",
        "\n",
        "\n",
        "\n",
        "# NETTOYAGE DES NOTES\n",
        "numeric_columns = ['press_rating']\n",
        "\n",
        "for col in numeric_columns:\n",
        "    if col in df_clean.columns:\n",
        "        print(f\"Nettoyage de la colonne {col}...\")\n",
        "        df_clean[col] = df_clean[col].apply(clean_numeric_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afa1639a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TRAITEMENT DU JEU DE DONNEES DE TEST\n",
        "numeric_columns = ['press_rating']\n",
        "\n",
        "for col in numeric_columns:\n",
        "    if col in df_test.columns:\n",
        "        print(f\"Nettoyage de la colonne {col}...\")\n",
        "        df_test[col] = df_test[col].apply(clean_numeric_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da1463fa",
      "metadata": {},
      "source": [
        "Extraire les informations temporelles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c29d462",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_month(date_str):\n",
        "    \"\"\"Extrait le mois à partir d'une date au format DD/MM/YYYY\"\"\"\n",
        "    if pd.isna(date_str):\n",
        "        return np.nan\n",
        "        \n",
        "    match = re.search(r'(\\d{1,2})/(\\d{1,2})/(\\d{4})', str(date_str))\n",
        "    if match:\n",
        "        return int(match.group(2))\n",
        "        \n",
        "    return np.nan\n",
        "\n",
        "def extract_year(date_str):\n",
        "    \"\"\"Extrait l'année à partir d'une date au format DD/MM/YYYY\"\"\"\n",
        "    if pd.isna(date_str):\n",
        "        return np.nan\n",
        "        \n",
        "    match = re.search(r'(\\d{1,2})/(\\d{1,2})/(\\d{4})', str(date_str))\n",
        "    if match:\n",
        "        return int(match.group(3))\n",
        "    \n",
        "    # Format YYYY uniquement\n",
        "    match = re.search(r'^(\\d{4})$', str(date_str).strip())\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "        \n",
        "    return np.nan\n",
        "\n",
        "def determine_season(month):\n",
        "    \"\"\"Détermine la saison en fonction du mois\"\"\"\n",
        "    if pd.isna(month):\n",
        "        return np.nan\n",
        "    month = int(month)\n",
        "    if month in [12, 1, 2]:\n",
        "        return 1  # Hiver\n",
        "    elif month in [3, 4, 5]:\n",
        "        return 2  # Printemps\n",
        "    elif month in [6, 7, 8]:\n",
        "        return 3  # Été\n",
        "    else:\n",
        "        return 4  # Automne\n",
        "\n",
        "def is_holiday_season(month, day=15):\n",
        "    \"\"\"Détermine si c'est une période de vacances scolaires\"\"\"\n",
        "    if pd.isna(month):\n",
        "        return np.nan\n",
        "    \n",
        "    month = int(month)\n",
        "    \n",
        "    # Vacances d'été (juillet-août)\n",
        "    if month in [7, 8]:\n",
        "        return 1\n",
        "    # Vacances de Noël (décembre)\n",
        "    elif month == 12:\n",
        "        return 1\n",
        "    # Vacances d'hiver (février)\n",
        "    elif month == 2:\n",
        "        return 1\n",
        "    # Vacances de printemps (avril)\n",
        "    elif month == 4:\n",
        "        return 1\n",
        "    # Vacances de la Toussaint (octobre)\n",
        "    elif month == 10:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "    \n",
        "\n",
        "\n",
        "# EXTRACTION DES INFORMATIONS TEMPORELLES\n",
        "if 'date_sortie_france' in df_clean.columns:\n",
        "    df_clean['annee_sortie'] = df_clean['date_sortie_france'].apply(extract_year)\n",
        "    df_clean['mois_sortie'] = df_clean['date_sortie_france'].apply(extract_month)\n",
        "    df_clean['saison_sortie'] = df_clean['mois_sortie'].apply(determine_season)\n",
        "    df_clean['vacances_scolaires'] = df_clean['mois_sortie'].apply(is_holiday_season)\n",
        "\n",
        "    # Créer des indicateurs pour les périodes clés de sortie\n",
        "    df_clean['sortie_ete'] = (df_clean['mois_sortie'].isin([6, 7, 8])).astype(int)\n",
        "    df_clean['sortie_fetes'] = (df_clean['mois_sortie'].isin([11, 12])).astype(int)\n",
        "    \n",
        "    # Post-COVID (après 2020)\n",
        "    df_clean['post_covid'] = (df_clean['annee_sortie'] >= 2020).astype(int)\n",
        "    \n",
        "    # Jour de la semaine de sortie\n",
        "    try:\n",
        "        df_clean['day_of_week'] = pd.to_datetime(\n",
        "            df_clean['date_sortie_france'], \n",
        "            format='%d/%m/%Y', \n",
        "            errors='coerce'\n",
        "        ).dt.dayofweek\n",
        "        \n",
        "        # Est-ce une sortie mercredi (jour traditionnel en France)\n",
        "        df_clean['is_wednesday_release'] = (df_clean['day_of_week'] == 2).astype(int)\n",
        "        \n",
        "        # Est-ce une sortie en week-end (vendredi-dimanche)\n",
        "        df_clean['is_weekend_release'] = df_clean['day_of_week'].isin([4, 5, 6]).astype(int)\n",
        "    except:\n",
        "        print(\"Impossible de calculer le jour de la semaine\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b766061",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TRAITEMENT DU JEU DE DONNEES DE TEST\n",
        "if 'date_sortie_france' in df_test.columns:\n",
        "    df_test['annee_sortie'] = df_test['date_sortie_france'].apply(extract_year)\n",
        "    df_test['mois_sortie'] = df_test['date_sortie_france'].apply(extract_month)\n",
        "    df_test['saison_sortie'] = df_test['mois_sortie'].apply(determine_season)\n",
        "    df_test['vacances_scolaires'] = df_test['mois_sortie'].apply(is_holiday_season)\n",
        "\n",
        "    # Créer des indicateurs pour les périodes clés de sortie\n",
        "    df_test['sortie_ete'] = (df_test['mois_sortie'].isin([6, 7, 8])).astype(int)\n",
        "    df_test['sortie_fetes'] = (df_test['mois_sortie'].isin([11, 12])).astype(int)\n",
        "    \n",
        "    # Post-COVID (après 2020)\n",
        "    df_test['post_covid'] = (df_test['annee_sortie'] >= 2020).astype(int)\n",
        "    \n",
        "    # Jour de la semaine de sortie\n",
        "    try:\n",
        "        df_test['day_of_week'] = pd.to_datetime(\n",
        "            df_test['date_sortie_france'], \n",
        "            format='%d/%m/%Y', \n",
        "            errors='coerce'\n",
        "        ).dt.dayofweek\n",
        "        \n",
        "        # Est-ce une sortie mercredi (jour traditionnel en France)\n",
        "        df_test['is_wednesday_release'] = (df_test['day_of_week'] == 2).astype(int)\n",
        "        \n",
        "        # Est-ce une sortie en week-end (vendredi-dimanche)\n",
        "        df_test['is_weekend_release'] = df_test['day_of_week'].isin([4, 5, 6]).astype(int)\n",
        "    except:\n",
        "        print(\"Impossible de calculer le jour de la semaine\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2de7817",
      "metadata": {},
      "source": [
        "Catégoriser le budget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6d7cd99",
      "metadata": {},
      "outputs": [],
      "source": [
        "def categorize_budget(budget):\n",
        "    \"\"\"Catégorise le budget en 4 niveaux\"\"\"\n",
        "    if pd.isna(budget):\n",
        "        return np.nan\n",
        "    elif budget < 10000000:  # Moins de 10 millions\n",
        "        return 1  # Petit budget\n",
        "    elif budget < 50000000:  # Entre 10 et 50 millions\n",
        "        return 2  # Budget moyen\n",
        "    elif budget < 100000000:  # Entre 50 et 100 millions\n",
        "        return 3  # Gros budget\n",
        "    else:  # 100 millions et plus\n",
        "        return 4  # Blockbuster\n",
        "\n",
        "df_clean['budget'] = pd.to_numeric(df_clean['budget'], errors='coerce')\n",
        "# Transformation logarithmique du budget\n",
        "if 'budget' in df_clean.columns:\n",
        "    df_clean['log_budget'] = np.log1p(df_clean['budget'])\n",
        "    \n",
        "    # Catégorisation du budget\n",
        "    df_clean['categorie_budget'] = df_clean['budget'].apply(categorize_budget)\n",
        "    \n",
        "    # Blockbusters d'été\n",
        "    budget_median = df_clean['budget'].median()\n",
        "    df_clean['is_summer_blockbuster'] = ((df_clean['mois_sortie'] >= 6) & \n",
        "                                        (df_clean['mois_sortie'] <= 8) & \n",
        "                                        (df_clean['budget'] > budget_median)).astype(int)\n",
        "    \n",
        "    # Ratio marketing/budget (estimation à partir de règles de l'industrie)\n",
        "    df_clean['marketing_ratio'] = np.where(\n",
        "        df_clean['budget'] > df_clean['budget'].quantile(0.75), 0.5,\n",
        "        np.where(df_clean['budget'] > df_clean['budget'].quantile(0.25), 0.3, 0.2)\n",
        "    )\n",
        "    df_clean['estimated_marketing_budget'] = df_clean['budget'] * df_clean['marketing_ratio']\n",
        "    df_clean['estimated_total_budget'] = df_clean['budget'] + df_clean['estimated_marketing_budget']\n",
        "    df_clean['log_total_budget'] = np.log1p(df_clean['estimated_total_budget'])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5b3ef10",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TRAITEMENT DU JEU DE DONNEES DE TEST\n",
        "if 'budget' in df_test.columns:\n",
        "    df_test['log_budget'] = np.log1p(df_test['budget'])\n",
        "    \n",
        "    # Catégorisation du budget\n",
        "    df_test['categorie_budget'] = df_test['budget'].apply(categorize_budget)\n",
        "    \n",
        "    # Blockbusters d'été\n",
        "    budget_median = df_test['budget'].median()\n",
        "    df_test['is_summer_blockbuster'] = ((df_test['mois_sortie'] >= 6) & \n",
        "                                        (df_test['mois_sortie'] <= 8) & \n",
        "                                        (df_test['budget'] > budget_median)).astype(int)\n",
        "    \n",
        "    # Ratio marketing/budget (estimation à partir de règles de l'industrie)\n",
        "    df_test['marketing_ratio'] = np.where(\n",
        "        df_test['budget'] > df_test['budget'].quantile(0.75), 0.5,\n",
        "        np.where(df_test['budget'] > df_test['budget'].quantile(0.25), 0.3, 0.2)\n",
        "    )\n",
        "    df_test['estimated_marketing_budget'] = df_test['budget'] * df_test['marketing_ratio']\n",
        "    df_test['estimated_total_budget'] = df_test['budget'] + df_test['estimated_marketing_budget']\n",
        "    df_test['log_total_budget'] = np.log1p(df_test['estimated_total_budget'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8826e66a",
      "metadata": {},
      "source": [
        "Traitement des acteurs et franchises"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49d05b55",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Caractéristique pour les films avec des stars importantes\n",
        "famous_actors = [\n",
        "                # Acteurs\n",
        "                'Leonardo DiCaprio', 'Dwayne Johnson', 'Brad Pitt', 'Tom Cruise', 'Ryan Reynolds',\n",
        "                'Robert Downey Jr', 'Chris Hemsworth', 'Chris Evans', 'Keanu Reeves', 'Will Smith',\n",
        "                'Johnny Depp', 'Matt Damon', 'Christian Bale', 'Timothée Chalamet', 'Jake Gyllenhaal',\n",
        "                'Benedict Cumberbatch', 'Tom Holland', 'Michael B. Jordan', 'Hugh Jackman', 'Oscar Isaac',\n",
        "                'Cillian Murphy', 'Adam Driver', 'Daniel Craig', 'Joaquin Phoenix', 'Mark Wahlberg',\n",
        "                'Denzel Washington', 'Tom Hanks', 'George Clooney', 'Ryan Gosling', 'Jamie Foxx',\n",
        "                'Idris Elba', 'Chris Pratt', 'Samuel L. Jackson', 'Jason Statham', 'Anthony Hopkins',\n",
        "                \n",
        "                # Actrices\n",
        "                'Margot Robbie', 'Scarlett Johansson', 'Jennifer Lawrence', 'Zendaya', 'Emma Stone',\n",
        "                'Natalie Portman', 'Florence Pugh', 'Gal Gadot', 'Anya Taylor-Joy', 'Cate Blanchett',\n",
        "                'Charlize Theron', 'Emily Blunt', 'Anne Hathaway', 'Jessica Chastain', 'Saoirse Ronan',\n",
        "                'Viola Davis', 'Brie Larson', 'Millie Bobby Brown', 'Salma Hayek', 'Penélope Cruz',\n",
        "                'Sandra Bullock', 'Angelina Jolie', 'Elizabeth Olsen', 'Rachel McAdams', 'Zoe Saldana',\n",
        "                'Meryl Streep', 'Nicole Kidman', 'Julia Roberts', 'Jennifer Aniston', 'Emma Watson',\n",
        "                \n",
        "                # Acteurs français\n",
        "                'Jean Dujardin', 'Omar Sy', 'Vincent Cassel', 'Gérard Depardieu', 'François Civil',\n",
        "                'Dany Boon', 'Guillaume Canet', 'Mathieu Amalric', 'Louis Garrel', 'Melvil Poupaud',\n",
        "                \n",
        "                # Actrices françaises\n",
        "                'Marion Cotillard', 'Léa Seydoux', 'Eva Green', 'Audrey Tautou', 'Juliette Binoche',\n",
        "                'Adèle Exarchopoulos', 'Isabelle Huppert', 'Mélanie Laurent', 'Sophie Marceau', 'Catherine Deneuve'\n",
        "                ]\n",
        "\n",
        "df_clean['has_famous_actor'] = df_clean['top_stars'].apply(\n",
        "                    lambda x: 1 if isinstance(x, str) and any(actor.lower() in str(x).lower() for actor in famous_actors) else 0\n",
        "                )\n",
        "\n",
        "# Feature pour les suites/franchises\n",
        "if 'titre_jpbox' in df_clean.columns:\n",
        "    franchise_indicators = ['2', '3', '4', '5', 'II', 'III', 'IV', 'V', 'saga', 'trilogy', \n",
        "                          'suite', 'chapitre', 'épisode', 'retour', 'episode']\n",
        "    df_clean['is_franchise'] = df_clean['titre_jpbox'].apply(\n",
        "        lambda x: 1 if isinstance(x, str) and any(ind in str(x).lower() for ind in franchise_indicators) else 0\n",
        "    )\n",
        "\n",
        "\n",
        "if 'top_stars' in df_clean.columns:\n",
        "    # Nombre total d'acteurs dans le casting\n",
        "    df_clean['star_count'] = df_clean['top_stars'].apply(\n",
        "        lambda x: len(str(x).split(',')) if not pd.isna(x) else 0\n",
        "    )\n",
        "    \n",
        "    # Présence d'une star majeure\n",
        "    df_clean['has_famous_actor'] = df_clean['top_stars'].apply(\n",
        "        lambda x: 1 if isinstance(x, str) and any(actor.lower() in str(x).lower() for actor in famous_actors) else 0\n",
        "    )\n",
        "    \n",
        "    # Nombre d'acteurs célèbres dans le casting\n",
        "    df_clean['famous_actor_count'] = df_clean['top_stars'].apply(\n",
        "        lambda x: sum(1 for actor in famous_actors if isinstance(x, str) and actor.lower() in str(x).lower()) if not pd.isna(x) else 0\n",
        "    )\n",
        "    \n",
        "    # Star power index (0-3) basé sur le nombre d'acteurs célèbres\n",
        "    df_clean['star_power'] = df_clean['famous_actor_count'].apply(\n",
        "        lambda x: min(3, x)  # Plafonné à 3 pour éviter les valeurs extrêmes\n",
        "    )\n",
        "    \n",
        "    # Présence spécifique d'acteurs à forte popularité (top 10)\n",
        "    top_actors = ['Leonardo DiCaprio', 'Dwayne Johnson', 'Brad Pitt', 'Tom Cruise', \n",
        "                 'Margot Robbie', 'Scarlett Johansson', 'Jennifer Lawrence', 'Robert Downey Jr',\n",
        "                 'Tom Holland', 'Zendaya']\n",
        "    \n",
        "    df_clean['has_top_tier_actor'] = df_clean['top_stars'].apply(\n",
        "        lambda x: 1 if isinstance(x, str) and any(actor.lower() in str(x).lower() for actor in top_actors) else 0\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e798b6d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TRAITEMENT DU JEU DE DONNEES DE TEST\n",
        "df_test['has_famous_actor'] = df_test['top_stars'].apply(\n",
        "                    lambda x: 1 if isinstance(x, str) and any(actor.lower() in str(x).lower() for actor in famous_actors) else 0\n",
        "                )\n",
        "\n",
        "# Feature pour les suites/franchises\n",
        "if 'titre_jpbox' in df_test.columns:\n",
        "    franchise_indicators = ['2', '3', '4', '5', 'II', 'III', 'IV', 'V', 'saga', 'trilogy', \n",
        "                          'suite', 'chapitre', 'épisode', 'retour', 'episode']\n",
        "    df_test['is_franchise'] = df_test['titre_jpbox'].apply(\n",
        "        lambda x: 1 if isinstance(x, str) and any(ind in str(x).lower() for ind in franchise_indicators) else 0\n",
        "    )\n",
        "\n",
        "\n",
        "if 'top_stars' in df_test.columns:\n",
        "    # Nombre total d'acteurs dans le casting\n",
        "    df_test['star_count'] = df_test['top_stars'].apply(\n",
        "        lambda x: len(str(x).split(',')) if not pd.isna(x) else 0\n",
        "    )\n",
        "    \n",
        "    # Présence d'une star majeure\n",
        "    df_test['has_famous_actor'] = df_test['top_stars'].apply(\n",
        "        lambda x: 1 if isinstance(x, str) and any(actor.lower() in str(x).lower() for actor in famous_actors) else 0\n",
        "    )\n",
        "    \n",
        "    # Nombre d'acteurs célèbres dans le casting\n",
        "    df_test['famous_actor_count'] = df_test['top_stars'].apply(\n",
        "        lambda x: sum(1 for actor in famous_actors if isinstance(x, str) and actor.lower() in str(x).lower()) if not pd.isna(x) else 0\n",
        "    )\n",
        "    \n",
        "    # Star power index (0-3) basé sur le nombre d'acteurs célèbres\n",
        "    df_test['star_power'] = df_test['famous_actor_count'].apply(\n",
        "        lambda x: min(3, x)  # Plafonné à 3 pour éviter les valeurs extrêmes\n",
        "    )\n",
        "    \n",
        "    # Présence spécifique d'acteurs à forte popularité (top 10)\n",
        "    top_actors = ['Leonardo DiCaprio', 'Dwayne Johnson', 'Brad Pitt', 'Tom Cruise', \n",
        "                 'Margot Robbie', 'Scarlett Johansson', 'Jennifer Lawrence', 'Robert Downey Jr',\n",
        "                 'Tom Holland', 'Zendaya']\n",
        "    \n",
        "    df_test['has_top_tier_actor'] = df_test['top_stars'].apply(\n",
        "        lambda x: 1 if isinstance(x, str) and any(actor.lower() in str(x).lower() for actor in top_actors) else 0\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20223622",
      "metadata": {},
      "source": [
        "Traitement des distributeurs / indicateur pour les gros studios \n",
        "\n",
        "Extraction des langues pour la nationalité"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "509b661b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Créer une caractéristique pour les gros distributeurs\n",
        "major_distributors = ['Disney', 'Warner', 'Universal', 'Sony', 'Paramount', 'Fox', \n",
        "                         'Gaumont', 'Pathé', 'Netflix', 'Amazon', 'StudioCanal']\n",
        "    \n",
        "for distributor in major_distributors:\n",
        "        df_clean[f'distributor_{distributor.lower()}'] = df_clean['distributor'].apply(\n",
        "            lambda x: 1 if isinstance(x, str) and distributor.lower() in str(x).lower() else 0\n",
        "        )\n",
        "    \n",
        "    # Indicateur pour les grands studios (majors)\n",
        "major_studios = ['Disney', 'Warner', 'Universal', 'Sony', 'Paramount', 'Fox']\n",
        "df_clean['is_major_studio'] = df_clean['distributor'].apply(\n",
        "        lambda x: 1 if isinstance(x, str) and any(studio.lower() in str(x).lower() for studio in major_studios) else 0\n",
        "    )\n",
        "\n",
        "# Création et nationalités via \"language\"\n",
        "df_clean['is_english'] = df_clean['languages'].apply(\n",
        "        lambda x: 1 if isinstance(x, str) and 'anglais' in str(x).lower() else 0\n",
        "    )\n",
        "df_clean['is_french'] = df_clean['languages'].apply(\n",
        "        lambda x: 1 if isinstance(x, str) and 'français' in str(x).lower() else 0\n",
        "    )\n",
        "\n",
        "# Création et nationalités via \"film_nationality\"\n",
        "df_clean['is_usa'] = df_clean['film_nationality'].apply(\n",
        "        lambda x: 1 if isinstance(x, str) and any(term in str(x).lower() for term in ['u.s.a', 'usa', 'états-unis']) else 0\n",
        "    )\n",
        "df_clean['is_france'] = df_clean['film_nationality'].apply(\n",
        "        lambda x: 1 if isinstance(x, str) and 'france' in str(x).lower() else 0\n",
        "    )\n",
        "df_clean['is_europe'] = df_clean['film_nationality'].apply(\n",
        "        lambda x: 1 if isinstance(x, str) and any(term in str(x).lower() for term in ['royaume-uni', 'allemagne', 'espagne', 'italie', 'belgique']) else 0\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb6ae755",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TRAITEMENT DU JEU DE DONNEES DE TEST\n",
        "major_distributors = ['Disney', 'Warner', 'Universal', 'Sony', 'Paramount', 'Fox', \n",
        "                         'Gaumont', 'Pathé', 'Netflix', 'Amazon', 'StudioCanal']\n",
        "    \n",
        "for distributor in major_distributors:\n",
        "        df_test[f'distributor_{distributor.lower()}'] = df_test['distributor'].apply(\n",
        "            lambda x: 1 if isinstance(x, str) and distributor.lower() in str(x).lower() else 0\n",
        "        )\n",
        "    \n",
        "    # Indicateur pour les grands studios (majors)\n",
        "major_studios = ['Disney', 'Warner', 'Universal', 'Sony', 'Paramount', 'Fox']\n",
        "df_test['is_major_studio'] = df_test['distributor'].apply(\n",
        "        lambda x: 1 if isinstance(x, str) and any(studio.lower() in str(x).lower() for studio in major_studios) else 0\n",
        "    )\n",
        "\n",
        "# Création et nationalités via \"language\"\n",
        "df_test['is_english'] = df_test['languages'].apply(\n",
        "        lambda x: 1 if isinstance(x, str) and 'anglais' in str(x).lower() else 0\n",
        "    )\n",
        "df_test['is_french'] = df_test['languages'].apply(\n",
        "        lambda x: 1 if isinstance(x, str) and 'français' in str(x).lower() else 0\n",
        "    )\n",
        "\n",
        "# Création et nationalités via \"film_nationality\"\n",
        "df_test['is_usa'] = df_test['film_nationality'].apply(\n",
        "        lambda x: 1 if isinstance(x, str) and any(term in str(x).lower() for term in ['u.s.a', 'usa', 'états-unis']) else 0\n",
        "    )\n",
        "df_test['is_france'] = df_test['film_nationality'].apply(\n",
        "        lambda x: 1 if isinstance(x, str) and 'france' in str(x).lower() else 0\n",
        "    )\n",
        "df_test['is_europe'] = df_test['film_nationality'].apply(\n",
        "        lambda x: 1 if isinstance(x, str) and any(term in str(x).lower() for term in ['royaume-uni', 'allemagne', 'espagne', 'italie', 'belgique']) else 0\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72d3f385",
      "metadata": {},
      "source": [
        "Traitement des informations ayant une portée sur le public cible\n",
        "\n",
        "Catégoriser par popularité"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd447e25",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Classification d'âge (restriction)\n",
        "if 'age_classification' in df_clean.columns:\n",
        "    df_clean['is_adult_only'] = df_clean['age_classification'].apply(\n",
        "        lambda x: 1 if isinstance(x, str) and any(term in str(x).lower() \n",
        "                                              for term in ['interdit', '16 ans', '18 ans', 'adulte'])\n",
        "        else 0\n",
        "    )\n",
        "\n",
        "# Nombre de critiques presse (indicateur d'attente médiatique avant sortie)\n",
        "if 'press_critics_count' in df_clean.columns:\n",
        "    # Extraire le nombre de critiques\n",
        "    df_clean['press_critics_count_num'] = df_clean['press_critics_count'].apply(\n",
        "        lambda x: int(re.search(r'(\\d+)', str(x)).group(1)) if isinstance(x, str) and re.search(r'(\\d+)', str(x)) else 0\n",
        "    )\n",
        "    \n",
        "    # Catégoriser par popularité\n",
        "    critics_median = df_clean['press_critics_count_num'].median()\n",
        "    df_clean['press_critics_count_high'] = (df_clean['press_critics_count_num'] > critics_median).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9a96771",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TRAITEMENT DU JEU DE DONNEES DE TEST\n",
        "if 'age_classification' in df_test.columns:\n",
        "    df_test['is_adult_only'] = df_test['age_classification'].apply(\n",
        "        lambda x: 1 if isinstance(x, str) and any(term in str(x).lower() \n",
        "                                              for term in ['interdit', '16 ans', '18 ans', 'adulte'])\n",
        "        else 0\n",
        "    )\n",
        "\n",
        "# Nombre de critiques presse (indicateur d'attente médiatique avant sortie)\n",
        "if 'press_critics_count' in df_test.columns:\n",
        "    # Extraire le nombre de critiques\n",
        "    df_test['press_critics_count_num'] = df_test['press_critics_count'].apply(\n",
        "        lambda x: int(re.search(r'(\\d+)', str(x)).group(1)) if isinstance(x, str) and re.search(r'(\\d+)', str(x)) else 0\n",
        "    )\n",
        "    \n",
        "    # Catégoriser par popularité\n",
        "    critics_median = df_test['press_critics_count_num'].median()\n",
        "    df_test['press_critics_count_high'] = (df_test['press_critics_count_num'] > critics_median).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fe3d927",
      "metadata": {},
      "source": [
        "Traitement approfondi de age_classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad08b58c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Classification par niveau de restriction\n",
        "def get_age_rating(classification):\n",
        "        if pd.isna(classification):\n",
        "            return np.nan\n",
        "            \n",
        "        classification = str(classification).lower()\n",
        "        \n",
        "        if 'tous publics' in classification or 'tout public' in classification:\n",
        "            return 0  # Tous publics\n",
        "        elif any(term in classification for term in ['10 ans', '10+']):\n",
        "            return 1  # 10+\n",
        "        elif any(term in classification for term in ['12 ans', '12+']):\n",
        "            return 2  # 12+\n",
        "        elif any(term in classification for term in ['13 ans', 'adolescent', '13+']):\n",
        "            return 2  # 13+\n",
        "        elif any(term in classification for term in ['16 ans', '16+']):\n",
        "            return 3  # 16+\n",
        "        elif any(term in classification for term in ['18 ans', 'interdit -18', 'interdit aux mineurs', 'adulte']):\n",
        "            return 4  # 18+\n",
        "        else:\n",
        "            return 0  # Par défaut tous publics si non spécifié\n",
        "        \n",
        "\n",
        "    # Classification binaire (tout public vs. restreint)\n",
        "df_clean['is_adult_only'] = df_clean['age_classification'].apply(\n",
        "        lambda x: 1 if isinstance(x, str) and any(term in str(x).lower() \n",
        "                                   for term in ['interdit', '16 ans', '18 ans', 'adulte'])\n",
        "        else 0\n",
        "    )\n",
        "    \n",
        "df_clean['age_rating'] = df_clean['age_classification'].apply(get_age_rating)\n",
        "    \n",
        "    # Interaction avec le genre (certains genres sont plus ou moins adaptés aux restrictions d'âge)\n",
        "for genre_col in [col for col in df_clean.columns if col.startswith('genre_principale_')]:\n",
        "        genre_name = genre_col.replace('genre_principale_', '')\n",
        "        df_clean[f'age_rating_x_{genre_name}'] = df_clean['age_rating'] * df_clean[genre_col]\n",
        "    \n",
        "    # Impact sur le budget marketing (films pour adultes ont souvent un marketing différent)\n",
        "if 'marketing_ratio' in df_clean.columns:\n",
        "        # Pour les films adultes, un ratio marketing/budget différent\n",
        "        age_factor = df_clean['age_rating'].apply(lambda x: 1 + (0.05 * x) if not pd.isna(x) else 1)\n",
        "        df_clean['age_adjusted_marketing'] = df_clean['marketing_ratio'] * age_factor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c19f51d",
      "metadata": {},
      "source": [
        "One-hot encoding et interactions budget/genre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40051446",
      "metadata": {},
      "outputs": [],
      "source": [
        "# One-hot encoding pour les variables catégorielles\n",
        "categorical_columns = []\n",
        "\n",
        "if 'genre_principale' in df_clean.columns:\n",
        "    categorical_columns.append('genre_principale')\n",
        "if 'saison_sortie' in df_clean.columns:\n",
        "    categorical_columns.append('saison_sortie')\n",
        "if 'categorie_budget' in df_clean.columns:\n",
        "    categorical_columns.append('categorie_budget')\n",
        "\n",
        "# One-hot encoding\n",
        "if categorical_columns:\n",
        "    df_clean = pd.get_dummies(df_clean, columns=categorical_columns, drop_first=False)\n",
        "    \n",
        "    # Lister les colonnes créées\n",
        "    genre_columns = [col for col in df_clean.columns if col.startswith('genre_principale_')]\n",
        "    saison_columns = [col for col in df_clean.columns if col.startswith('saison_sortie_')]\n",
        "    budget_cat_columns = [col for col in df_clean.columns if col.startswith('categorie_budget_')]\n",
        "    \n",
        "    print(f\"Colonnes de genre créées: {genre_columns}\")\n",
        "    print(f\"Colonnes de saison créées: {saison_columns}\")\n",
        "    print(f\"Colonnes de catégorie budget créées: {budget_cat_columns}\")\n",
        "\n",
        "# Créer des features d'interaction entre le budget et les genres\n",
        "if 'budget' in df_clean.columns:\n",
        "    # Utiliser seulement les genres les plus importants\n",
        "    main_genres = ['action', 'comédie', 'drame', 'animation', 'fantastique', 'science-fiction']\n",
        "    \n",
        "    for genre in main_genres:\n",
        "        genre_col = [col for col in df_clean.columns if genre.lower() in col.lower() and 'genre_' in col]\n",
        "        if genre_col:\n",
        "            df_clean[f'budget_x_genre_{genre}'] = df_clean['budget'] * df_clean[genre_col[0]]\n",
        "    \n",
        "    # Interaction entre budget et période de sortie\n",
        "    if 'sortie_ete' in df_clean.columns:\n",
        "        df_clean['budget_x_sortie_ete'] = df_clean['budget'] * df_clean['sortie_ete']\n",
        "    if 'sortie_fetes' in df_clean.columns:\n",
        "        df_clean['budget_x_sortie_fetes'] = df_clean['budget'] * df_clean['sortie_fetes']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abd52fd2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TRAITEMENT DU JEU DE DONNEES DE TEST\n",
        "# One-hot encoding pour les variables catégorielles\n",
        "categorical_columns = []\n",
        "\n",
        "if 'genre_principale' in df_test.columns:\n",
        "    categorical_columns.append('genre_principale')\n",
        "if 'saison_sortie' in df_test.columns:\n",
        "    categorical_columns.append('saison_sortie')\n",
        "if 'categorie_budget' in df_test.columns:\n",
        "    categorical_columns.append('categorie_budget')\n",
        "\n",
        "# One-hot encoding\n",
        "if categorical_columns:\n",
        "    df_test= pd.get_dummies(df_test, columns=categorical_columns, drop_first=False)\n",
        "    \n",
        "    # Lister les colonnes créées\n",
        "    genre_columns = [col for col in df_test.columns if col.startswith('genre_principale_')]\n",
        "    saison_columns = [col for col in df_test.columns if col.startswith('saison_sortie_')]\n",
        "    budget_cat_columns = [col for col in df_test.columns if col.startswith('categorie_budget_')]\n",
        "    \n",
        "    print(f\"Colonnes de genre créées: {genre_columns}\")\n",
        "    print(f\"Colonnes de saison créées: {saison_columns}\")\n",
        "    print(f\"Colonnes de catégorie budget créées: {budget_cat_columns}\")\n",
        "\n",
        "# Créer des features d'interaction entre le budget et les genres\n",
        "if 'budget' in df_test.columns:\n",
        "    # Utiliser seulement les genres les plus importants\n",
        "    main_genres = ['action', 'comédie', 'drame', 'animation', 'fantastique', 'science-fiction']\n",
        "    \n",
        "    for genre in main_genres:\n",
        "        genre_col = [col for col in df_test.columns if genre.lower() in col.lower() and 'genre_' in col]\n",
        "        if genre_col:\n",
        "            df_test[f'budget_x_genre_{genre}'] = df_test['budget'] * df_test[genre_col[0]]\n",
        "    \n",
        "    # Interaction entre budget et période de sortie\n",
        "    if 'sortie_ete' in df_test.columns:\n",
        "        df_test['budget_x_sortie_ete'] = df_test['budget'] * df_test['sortie_ete']\n",
        "    if 'sortie_fetes' in df_test.columns:\n",
        "        df_test['budget_x_sortie_fetes'] = df_test['budget'] * df_test['sortie_fetes']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5b11ab1",
      "metadata": {},
      "source": [
        "Traitement de \"trailer_views\" approfondi\n",
        "\n",
        "Création d'une feature pour le nombre de prix et nominations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b399ad5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Traitement des vues de bande-annonce (feature prédictive importante)\n",
        "if 'trailer_views' in df_clean.columns:\n",
        "    # Nettoyer les vues de bande-annonce en tenant compte des caractères spéciaux\n",
        "    df_clean['trailer_views_clean'] = df_clean['trailer_views'].apply(\n",
        "        lambda x: float(re.sub(r'[^\\d.]', '', str(x))) \n",
        "        if isinstance(x, str) and any(c.isdigit() for c in str(x)) else np.nan\n",
        "    )\n",
        "    \n",
        "    # Transformation logarithmique des vues (pour normaliser)\n",
        "    df_clean['log_trailer_views'] = np.log1p(df_clean['trailer_views_clean'])\n",
        "    \n",
        "    # Catégorisation des vues\n",
        "    trailer_views_median = df_clean['trailer_views_clean'].median()\n",
        "    df_clean['high_trailer_views'] = (df_clean['trailer_views_clean'] > trailer_views_median).astype(int)\n",
        "\n",
        "# Traitement des récompenses et nominations (comme indicateurs de qualité prévisible)\n",
        "if 'awards' in df_clean.columns:\n",
        "    # Extraction du nombre de prix et nominations\n",
        "    def extract_awards_count(awards_text):\n",
        "        if pd.isna(awards_text):\n",
        "            return 0, 0\n",
        "        \n",
        "        awards_text = str(awards_text).lower()\n",
        "        \n",
        "        # Extraire le nombre de prix\n",
        "        prix_match = re.search(r'(\\d+)\\s+prix', awards_text)\n",
        "        prix_count = int(prix_match.group(1)) if prix_match else 0\n",
        "        \n",
        "        # Extraire le nombre de nominations\n",
        "        nom_match = re.search(r'(\\d+)\\s+nomination', awards_text)\n",
        "        nom_count = int(nom_match.group(1)) if nom_match else 0\n",
        "        \n",
        "        return prix_count, nom_count\n",
        "    \n",
        "    # Créer des colonnes pour les prix et nominations\n",
        "    df_clean[['prix_count', 'nomination_count']] = pd.DataFrame(\n",
        "        df_clean['awards'].apply(extract_awards_count).tolist(),\n",
        "        index=df_clean.index\n",
        "    )\n",
        "    \n",
        "    # Feature combinée (prix ont plus de poids)\n",
        "    df_clean['award_score'] = df_clean['prix_count'] * 2 + df_clean['nomination_count']\n",
        "    \n",
        "    # Indicateur de film primé\n",
        "    df_clean['is_awarded'] = (df_clean['prix_count'] > 0).astype(int)\n",
        "\n",
        "     # Interaction avec les prix (effet multiplicateur des récompenses sur les vues)\n",
        "    df_clean['trailer_views_x_awards'] = df_clean['trailer_views_clean'] * df_clean['prix_count']\n",
        "        \n",
        "        # Ratio prix/vues (efficacité de conversion des récompenses en vues)\n",
        "    non_zero_views = df_clean['trailer_views_clean'].replace(0, np.nan)\n",
        "    df_clean['awards_per_view'] = df_clean['prix_count'] / non_zero_views\n",
        "        \n",
        "    if 'nomination_count' in df_clean.columns:\n",
        "        # Interaction avec les nominations\n",
        "        df_clean['trailer_views_x_nominations'] = df_clean['trailer_views_clean'] * df_clean['nomination_count']\n",
        "        \n",
        "    if 'award_score' in df_clean.columns:\n",
        "        # Interaction avec le score combiné awards/nominations\n",
        "        df_clean['trailer_views_x_award_score'] = df_clean['trailer_views_clean'] * df_clean['award_score']\n",
        "        \n",
        "        # Indicateur des films à haute visibilité et reconnaissance critique\n",
        "        views_threshold = df_clean['trailer_views_clean'].quantile(0.75)\n",
        "        df_clean['high_visibility_acclaimed'] = ((df_clean['trailer_views_clean'] > views_threshold) & \n",
        "                                               (df_clean['award_score'] > 0)).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff3a919c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TRAITEMENT DU JEU DE DONNEES DE TEST\n",
        "# Traitement des vues de bande-annonce\n",
        "if 'trailer_views' in df_test.columns:\n",
        "    # Nettoyer les vues de bande-annonce en tenant compte des caractères spéciaux\n",
        "    df_test['trailer_views_clean'] = df_test['trailer_views'].apply(\n",
        "        lambda x: float(re.sub(r'[^\\d.]', '', str(x))) \n",
        "        if isinstance(x, str) and any(c.isdigit() for c in str(x)) else np.nan\n",
        "    )\n",
        "    \n",
        "    # Transformation logarithmique des vues\n",
        "    df_test['log_trailer_views'] = np.log1p(df_test['trailer_views_clean'])\n",
        "    \n",
        "    # Catégorisation des vues\n",
        "    trailer_views_median = df_test['trailer_views_clean'].median()\n",
        "    df_test['high_trailer_views'] = (df_test['trailer_views_clean'] > trailer_views_median).astype(int)\n",
        "\n",
        "# Traitement des récompenses et nominations\n",
        "if 'awards' in df_test.columns:\n",
        "    # Extraction du nombre de prix et nominations\n",
        "    def extract_awards_count(awards_text):\n",
        "        if pd.isna(awards_text):\n",
        "            return 0, 0\n",
        "        \n",
        "        awards_text = str(awards_text).lower()\n",
        "        \n",
        "        # Extraire le nombre de prix\n",
        "        prix_match = re.search(r'(\\d+)\\s+prix', awards_text)\n",
        "        prix_count = int(prix_match.group(1)) if prix_match else 0\n",
        "        \n",
        "        # Extraire le nombre de nominations\n",
        "        nom_match = re.search(r'(\\d+)\\s+nomination', awards_text)\n",
        "        nom_count = int(nom_match.group(1)) if nom_match else 0\n",
        "        \n",
        "        return prix_count, nom_count\n",
        "    \n",
        "    # Extraire les prix et nominations avec une approche plus robuste\n",
        "    awards_data = df_test['awards'].apply(extract_awards_count)\n",
        "    prix_data = [item[0] for item in awards_data]\n",
        "    nomination_data = [item[1] for item in awards_data]\n",
        "    \n",
        "    # Assigner les valeurs individuellement\n",
        "    df_test['prix_count'] = prix_data\n",
        "    df_test['nomination_count'] = nomination_data\n",
        "    \n",
        "    # Feature combinée (prix ont plus de poids)\n",
        "    df_test['award_score'] = df_test['prix_count'] * 2 + df_test['nomination_count']\n",
        "    \n",
        "    # Indicateur de film primé\n",
        "    df_test['is_awarded'] = (df_test['prix_count'] > 0).astype(int)\n",
        "    \n",
        "    # Interaction avec les prix (effet multiplicateur des récompenses sur les vues)\n",
        "    if 'trailer_views_clean' in df_test.columns:\n",
        "        df_test['trailer_views_x_awards'] = df_test['trailer_views_clean'] * df_test['prix_count']\n",
        "        \n",
        "        # Ratio prix/vues (efficacité de conversion des récompenses en vues)\n",
        "        non_zero_views = df_test['trailer_views_clean'].replace(0, np.nan)\n",
        "        df_test['awards_per_view'] = df_test['prix_count'] / non_zero_views\n",
        "        \n",
        "        if 'nomination_count' in df_test.columns:\n",
        "            # Interaction avec les nominations\n",
        "            df_test['trailer_views_x_nominations'] = df_test['trailer_views_clean'] * df_test['nomination_count']\n",
        "        \n",
        "        if 'award_score' in df_test.columns:\n",
        "            # Interaction avec le score combiné awards/nominations\n",
        "            df_test['trailer_views_x_award_score'] = df_test['trailer_views_clean'] * df_test['award_score']\n",
        "            \n",
        "            # Indicateur des films à haute visibilité et reconnaissance critique\n",
        "            views_threshold = df_test['trailer_views_clean'].quantile(0.75)\n",
        "            df_test['high_visibility_acclaimed'] = ((df_test['trailer_views_clean'] > views_threshold) & \n",
        "                                                 (df_test['award_score'] > 0)).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67a163c8",
      "metadata": {},
      "source": [
        "Préparation de la Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "231286e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transformation logarithmique de la variable cible\n",
        "if 'box_office_demarrage' in df_clean.columns:\n",
        "    # Vérifier le type et convertir toutes les valeurs en numériques\n",
        "    df_clean['box_office_demarrage'] = pd.to_numeric(df_clean['box_office_demarrage'], errors='coerce')\n",
        "    \n",
        "    # Remplacer les valeurs négatives par NaN (car log ne fonctionne pas sur les nombres négatifs)\n",
        "    df_clean.loc[df_clean['box_office_demarrage'] < 0, 'box_office_demarrage'] = np.nan\n",
        "    \n",
        "    # Appliquer la transformation logarithmique\n",
        "    df_clean['log_box_office_demarrage'] = np.log1p(df_clean['box_office_demarrage'])\n",
        "    \n",
        "    # Afficher des informations sur les transformations\n",
        "    print(f\"Valeurs nulles après conversion: {df_clean['box_office_demarrage'].isna().sum()}\")\n",
        "    print(f\"Valeurs transformées en log: {df_clean['log_box_office_demarrage'].notna().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ebd87c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transformation logarithmique de la variable cible\n",
        "if 'box_office_demarrage' in df_test.columns:\n",
        "    df_test['log_box_office_demarrage'] = np.log1p(df_test['box_office_demarrage'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c14e91bc",
      "metadata": {},
      "source": [
        "Sélection des features "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d05f4321",
      "metadata": {},
      "outputs": [],
      "source": [
        "features_selection = {\n",
        "    # 1. Features de base (durée et info film)\n",
        "    'base': [col for col in df_clean.columns if col in ['duree_minutes', 'duree', 'duree_film']],\n",
        "    \n",
        "    # 2. Features budgétaires\n",
        "    'budget': [col for col in df_clean.columns \n",
        "               if 'budget' in col.lower() \n",
        "               and 'budget_x_' not in col],\n",
        "    \n",
        "    # 3. Marketing\n",
        "    'marketing': [col for col in df_clean.columns if 'marketing' in col.lower()],\n",
        "    \n",
        "    # 4. Features temporelles\n",
        "    'temporel': [\n",
        "        col for col in df_clean.columns \n",
        "        if any(term in col for term in [\n",
        "            'mois_sortie', 'annee_sortie', 'saison_sortie', \n",
        "            'vacances_scolaires', 'sortie_ete', 'sortie_fetes', 'post_covid'\n",
        "        ]) or col.startswith('saison_sortie_') or col.startswith('mois_')\n",
        "    ],\n",
        "    \n",
        "    # 5. Features de jour de sortie\n",
        "    'jour_sortie': [\n",
        "        col for col in df_clean.columns \n",
        "        if 'wednesday' in col.lower() or 'weekend' in col.lower() or 'mercredi' in col.lower()\n",
        "    ],\n",
        "    \n",
        "    # 6. Genre principal\n",
        "    'genre_principal': [col for col in df_clean.columns if col.startswith('genre_principale_')],\n",
        "    \n",
        "    # 7. Genres associés\n",
        "    'genre_associe': [\n",
        "        col for col in df_clean.columns \n",
        "        if col.startswith('genre_') and not col.startswith('genre_principale_')\n",
        "        and not 'budget_x_genre' in col\n",
        "    ],\n",
        "    \n",
        "    # 8. Interaction budget-genre\n",
        "    'interaction': [col for col in df_clean.columns if 'budget_x_' in col],\n",
        "    \n",
        "    # 9. Distributeur\n",
        "    'distributeur': [\n",
        "        col for col in df_clean.columns \n",
        "        if col.startswith('distributor_') or col == 'is_major_studio'\n",
        "    ],\n",
        "    \n",
        "    # 10. Origine et langue\n",
        "    'origine': [col for col in df_clean.columns \n",
        "                if col in ['is_english', 'is_french', 'is_usa', 'is_europe']],\n",
        "    \n",
        "    # 11. Acteurs et franchise\n",
        "    'acteurs': [col for col in df_clean.columns \n",
        "                if col in ['star_count', 'has_famous_actor', 'is_franchise']],\n",
        "    \n",
        "    # 12. Press rating (disponible avant sortie)\n",
        "    'presse': [col for col in df_clean.columns if 'press_rating' in col.lower()],\n",
        "    \n",
        "    # 13. Trailer views\n",
        "    'trailer': [col for col in df_clean.columns \n",
        "                if 'trailer_views' in col.lower() or 'log_trailer_views' in col.lower() \n",
        "                or 'high_trailer_views' in col.lower()],\n",
        "    \n",
        "    # 14. Awards/nominations (provenant de festivals avant sortie générale)\n",
        "    'awards': [col for col in df_clean.columns \n",
        "               if 'award' in col.lower() or 'prix_count' in col.lower() \n",
        "               or 'nomination_count' in col.lower() or 'is_awarded' in col.lower()],\n",
        "    \n",
        "    # 15. Public cible\n",
        "    'target_audience': [col for col in df_clean.columns \n",
        "                      if col in ['is_adult_only']]\n",
        "}\n",
        "\n",
        "features_to_exclude = [\n",
        "    'box_office_france', 'fr_entry_week', 'us_entry_week', 'fr_entries', \n",
        "    'note_moyenne', 'viewer_critics_count', 'viewer_rating'\n",
        "]\n",
        "\n",
        "# Aplatir la liste de features\n",
        "selected_features = []\n",
        "for category, features in features_selection.items():\n",
        "    # Filtrer uniquement les colonnes qui existent réellement et qui ne sont pas à exclure\n",
        "    existing_features = [f for f in features if f in df_clean.columns \n",
        "                         and not any(exclude in f for exclude in features_to_exclude)]\n",
        "    selected_features.extend(existing_features)\n",
        "    print(f\"{category}: {len(existing_features)} features\")\n",
        "\n",
        "# Éliminer les doublons\n",
        "selected_features = list(set(selected_features))\n",
        "\n",
        "print(f\"\\nNombre total de features sélectionnées: {len(selected_features)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ca20a3c",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(selected_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99b64c45",
      "metadata": {},
      "source": [
        "Préparation des données pour la modélisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49fadd95",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Préparer X et y\n",
        "X = df_clean[selected_features].copy()\n",
        "y = df_clean['box_office_demarrage'].copy()\n",
        "y_log = df_clean['log_box_office_demarrage'].copy()\n",
        "\n",
        "# 1. Vérifier et corriger les colonnes non numériques\n",
        "for col in X.columns:\n",
        "    # Vérifier si la colonne contient des valeurs non numériques\n",
        "    if X[col].dtype == 'object':\n",
        "        print(f\"Colonne non numérique détectée: {col}\")\n",
        "        \n",
        "        # Tentative de conversion\n",
        "        try:\n",
        "            X[col] = X[col].apply(lambda x: str(x).replace(' ', '') if isinstance(x, str) else x)\n",
        "            X[col] = pd.to_numeric(X[col], errors='coerce')\n",
        "            print(f\"  → Conversion réussie pour {col}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  → Erreur lors de la conversion: {e}\")\n",
        "            # Supprimer les colonnes qui ne peuvent pas être converties\n",
        "            X = X.drop(columns=[col])\n",
        "            print(f\"  → Colonne {col} supprimée\")\n",
        "\n",
        "print(f\"Nombre de colonnes après nettoyage: {X.shape[1]}\")\n",
        "\n",
        "# 2. Vérifier les valeurs manquantes avant imputation\n",
        "print(f\"Valeurs manquantes par colonne:\")\n",
        "missing_values = X.isna().sum()\n",
        "print(missing_values[missing_values > 0])\n",
        "\n",
        "# 3. Imputation avec gestion d'erreurs\n",
        "try:\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    X_imputed = imputer.fit_transform(X)\n",
        "    print(\"Imputation réussie!\")\n",
        "except Exception as e:\n",
        "    print(f\"Erreur lors de l'imputation: {e}\")\n",
        "    # Stratégie alternative: utiliser la moyenne au lieu de la médiane\n",
        "    try:\n",
        "        print(\"Tentative avec la stratégie 'mean'...\")\n",
        "        imputer = SimpleImputer(strategy='mean')\n",
        "        X_imputed = imputer.fit_transform(X)\n",
        "        print(\"Imputation avec 'mean' réussie!\")\n",
        "    except Exception as e2:\n",
        "        print(f\"Erreur avec 'mean': {e2}\")\n",
        "        # Dernier recours: suppression des valeurs manquantes\n",
        "        print(\"Suppression des lignes avec valeurs manquantes...\")\n",
        "        # Obtenez les indices des lignes sans valeurs manquantes\n",
        "        complete_indices = X.dropna().index\n",
        "        X = X.loc[complete_indices]\n",
        "        y = y.loc[complete_indices]\n",
        "        y_log = y_log.loc[complete_indices]\n",
        "        X_imputed = X.values\n",
        "        print(f\"Données réduites à {len(X)} lignes\")\n",
        "\n",
        "# 4. Standardisation avec gestion d'erreurs\n",
        "try:\n",
        "    scaler = RobustScaler()\n",
        "    X_scaled = scaler.fit_transform(X_imputed)\n",
        "    print(\"Standardisation réussie!\")\n",
        "except Exception as e:\n",
        "    print(f\"Erreur lors de la standardisation: {e}\")\n",
        "    # Si la standardisation échoue, utilisez les données imputées sans standardisation\n",
        "    X_scaled = X_imputed\n",
        "    print(\"Utilisation des données imputées sans standardisation\")\n",
        "\n",
        "# 5. Vérifiez que X_scaled ne contient pas de NaN ou d'infini\n",
        "if np.isnan(X_scaled).any() or np.isinf(X_scaled).any():\n",
        "    print(\"Attention: X_scaled contient des NaN ou infini\")\n",
        "    # Remplacer les NaN et infini par 0\n",
        "    X_scaled = np.nan_to_num(X_scaled)\n",
        "    print(\"Les valeurs NaN et infini ont été remplacées par 0\")\n",
        "\n",
        "print(f\"Dimensions finales de X_scaled: {X_scaled.shape}\")\n",
        "\n",
        "# 6. Train-test split\n",
        "X_train, X_test, y_train_log, y_test_log = train_test_split(\n",
        "    X_scaled, y_log, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Conserver également les valeurs y non logarithmiques pour l'évaluation\n",
        "_, _, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5590bc4",
      "metadata": {},
      "source": [
        "Entrainement du modèle XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae6d9045",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vérifier et nettoyer les valeurs problématiques dans y_train_log\n",
        "print(f\"NaN dans y_train_log: {np.isnan(y_train_log).sum()}\")\n",
        "print(f\"Min: {y_train_log.min()}, Max: {y_train_log.max()}\")\n",
        "\n",
        "# Filtrer les entrées avec des valeurs NaN\n",
        "valid_indices = ~np.isnan(y_train_log)\n",
        "if valid_indices.sum() < len(y_train_log):\n",
        "    print(f\"Suppression de {len(y_train_log) - valid_indices.sum()} entrées avec valeurs NaN\")\n",
        "    X_train = X_train[valid_indices]\n",
        "    y_train_log = y_train_log[valid_indices]\n",
        "    y_train = y_train[valid_indices]\n",
        "    \n",
        "print(f\"Nombre final d'entrées: {len(y_train_log)}\")\n",
        "\n",
        "# Entraînement du modèle XGBoost\n",
        "print(\"Entraînement du modèle XGBoost...\")\n",
        "xgb_model = XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    min_child_weight=3,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    gamma=0.1,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train, y_train_log)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca34385a",
      "metadata": {},
      "source": [
        "Gridsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "380c1979",
      "metadata": {},
      "outputs": [],
      "source": [
        "#GRIDSEARCH 1 \n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Définition de la fonction d'évaluation\n",
        "def evaluate_model(model, X, y_log, y_original, model_name=\"Modèle\"):\n",
        "    \"\"\"Évalue un modèle et affiche les métriques\"\"\"\n",
        "    # Filtrer les valeurs NaN\n",
        "    valid_indices = ~np.isnan(y_log) & ~np.isnan(y_original)\n",
        "    if valid_indices.sum() < len(y_log):\n",
        "        print(f\"Suppression de {len(y_log) - valid_indices.sum()} entrées avec NaN\")\n",
        "        X = X[valid_indices]\n",
        "        y_log = y_log[valid_indices]\n",
        "        y_original = y_original[valid_indices]\n",
        "    \n",
        "    # Prédictions et conversion\n",
        "    y_pred_log = model.predict(X)\n",
        "    y_pred = np.expm1(y_pred_log)\n",
        "    \n",
        "    # Calcul des métriques\n",
        "    r2 = r2_score(y_original, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_original, y_pred))\n",
        "    mae = mean_absolute_error(y_original, y_pred)\n",
        "    r2_log = r2_score(y_log, y_pred_log)\n",
        "    \n",
        "    # Affichage des résultats\n",
        "    print(f\"\\nRésultats du modèle {model_name}:\")\n",
        "    print(f\"R² = {r2:.4f}, R² (log) = {r2_log:.4f}\")\n",
        "    print(f\"RMSE = {rmse:.2f}, MAE = {mae:.2f}\")\n",
        "    \n",
        "    return {'r2': r2, 'rmse': rmse, 'r2_log': r2_log, 'y_pred': y_pred, 'mae': mae}\n",
        "\n",
        "# Enregistrer le temps de début\n",
        "start_time = time.time()\n",
        "\n",
        "# Pour réduire le temps de calcul, utilisez une recherche par étapes\n",
        "# D'abord, optimisez max_depth et learning_rate\n",
        "param_grid_step1 = {\n",
        "    'max_depth': [5, 6, 7, 8],\n",
        "    'learning_rate': [0.03, 0.05, 0.08]\n",
        "}\n",
        "\n",
        "# Modèle XGBoost avec les autres paramètres comme dans votre modèle original\n",
        "xgb_model_grid = XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    n_estimators=200,\n",
        "    min_child_weight=3,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    gamma=0.1,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Configuration de la validation croisée\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Configuration du GridSearchCV\n",
        "print(\"Étape 1: Optimisation de max_depth et learning_rate...\")\n",
        "grid_search_step1 = GridSearchCV(\n",
        "    estimator=xgb_model_grid,\n",
        "    param_grid=param_grid_step1,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Exécuter la recherche étape 1\n",
        "grid_search_step1.fit(X_train, y_train_log, eval_set=[(X_train, y_train_log)])\n",
        "\n",
        "# Récupérer les meilleurs paramètres de l'étape 1\n",
        "best_params_step1 = grid_search_step1.best_params_\n",
        "print(f\"Meilleurs paramètres de l'étape 1: {best_params_step1}\")\n",
        "\n",
        "# Étape 2: Optimiser min_child_weight et gamma avec les meilleurs max_depth et learning_rate\n",
        "param_grid_step2 = {\n",
        "    'min_child_weight': [2, 3, 4],\n",
        "    'gamma': [0.05, 0.1, 0.15]\n",
        "}\n",
        "\n",
        "# Créer un nouveau modèle avec les meilleurs paramètres de l'étape 1\n",
        "xgb_model_grid2 = XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    n_estimators=200,\n",
        "    max_depth=best_params_step1['max_depth'],\n",
        "    learning_rate=best_params_step1['learning_rate'],\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Étape 2: Optimisation de min_child_weight et gamma...\")\n",
        "grid_search_step2 = GridSearchCV(\n",
        "    estimator=xgb_model_grid2,\n",
        "    param_grid=param_grid_step2,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Exécuter la recherche étape 2\n",
        "grid_search_step2.fit(X_train, y_train_log, eval_set=[(X_train, y_train_log)])\n",
        "\n",
        "# Récupérer les meilleurs paramètres de l'étape 2\n",
        "best_params_step2 = grid_search_step2.best_params_\n",
        "print(f\"Meilleurs paramètres de l'étape 2: {best_params_step2}\")\n",
        "\n",
        "# Étape 3: Optimiser subsample et colsample_bytree\n",
        "param_grid_step3 = {\n",
        "    'subsample': [0.7, 0.8, 0.9],\n",
        "    'colsample_bytree': [0.7, 0.8, 0.9]\n",
        "}\n",
        "\n",
        "# Créer un nouveau modèle avec les meilleurs paramètres des étapes 1 et 2\n",
        "xgb_model_grid3 = XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    n_estimators=200,\n",
        "    max_depth=best_params_step1['max_depth'],\n",
        "    learning_rate=best_params_step1['learning_rate'],\n",
        "    min_child_weight=best_params_step2['min_child_weight'],\n",
        "    gamma=best_params_step2['gamma'],\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Étape 3: Optimisation de subsample et colsample_bytree...\")\n",
        "grid_search_step3 = GridSearchCV(\n",
        "    estimator=xgb_model_grid3,\n",
        "    param_grid=param_grid_step3,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Exécuter la recherche étape 3\n",
        "grid_search_step3.fit(X_train, y_train_log, eval_set=[(X_train, y_train_log)])\n",
        "\n",
        "# Récupérer les meilleurs paramètres de l'étape 3\n",
        "best_params_step3 = grid_search_step3.best_params_\n",
        "print(f\"Meilleurs paramètres de l'étape 3: {best_params_step3}\")\n",
        "\n",
        "# Créer le modèle final avec tous les meilleurs paramètres\n",
        "final_params = {**best_params_step1, **best_params_step2, **best_params_step3}\n",
        "print(\"\\nMeilleurs paramètres combinés:\")\n",
        "for param, value in final_params.items():\n",
        "    print(f\"  {param}: {value}\")\n",
        "\n",
        "# Entraîner le modèle final\n",
        "final_model = XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    n_estimators=200,\n",
        "    **final_params,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"\\nEntraînement du modèle final avec les meilleurs paramètres...\")\n",
        "final_model.fit(X_train, y_train_log, eval_set=[(X_train, y_train_log)])\n",
        "\n",
        "# Afficher le temps total d'exécution\n",
        "end_time = time.time()\n",
        "print(f\"Temps total de l'optimisation: {(end_time - start_time)/60:.2f} minutes\")\n",
        "\n",
        "# Évaluer d'abord le modèle original\n",
        "original_model = xgb_model  # Votre modèle XGBoost original déjà entraîné\n",
        "original_results = evaluate_model(original_model, X_test, y_test_log, y_test, \"XGBoost Original\")\n",
        "\n",
        "# Évaluation du modèle final\n",
        "final_results = evaluate_model(final_model, X_test, y_test_log, y_test, \"XGBoost Final\")\n",
        "\n",
        "# Comparaison avec le modèle original\n",
        "print(\"\\n===== COMPARAISON DES MODÈLES =====\")\n",
        "print(f\"R² Original: {original_results['r2']:.4f}, R² Optimisé: {final_results['r2']:.4f}\")\n",
        "improvement_r2 = ((final_results['r2'] - original_results['r2']) / abs(original_results['r2'])) * 100\n",
        "print(f\"Amélioration R²: {improvement_r2:.2f}%\")\n",
        "\n",
        "print(f\"RMSE Original: {original_results['rmse']:.2f}, RMSE Optimisé: {final_results['rmse']:.2f}\")\n",
        "improvement_rmse = ((original_results['rmse'] - final_results['rmse']) / original_results['rmse']) * 100\n",
        "print(f\"Réduction RMSE: {improvement_rmse:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d415e78b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ⏱ Enregistrer le temps de début\n",
        "start_time = time.time()\n",
        "\n",
        "# 🔧 Grille d'hyperparamètres stratégique\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'n_estimators': [100, 200],\n",
        "    'colsample_bytree': [0.7, 0.9],\n",
        "    'subsample': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "# 📦 Modèle XGBoost avec early stopping intégré\n",
        "xgb_model_grid = XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    min_child_weight=3,\n",
        "    gamma=0.1,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=42,\n",
        "    early_stopping_rounds=20\n",
        ")\n",
        "\n",
        "# 🔁 Validation croisée\n",
        "cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 🔍 GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=xgb_model_grid,\n",
        "    param_grid=param_grid,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 🎯 Ensemble de validation pour early stopping\n",
        "eval_set = [(X_train, y_train_log)]\n",
        "\n",
        "print(\"🚀 Début de la recherche par grille...\")\n",
        "grid_search.fit(X_train, y_train_log, eval_set=eval_set)\n",
        "\n",
        "# ⏱ Temps d’exécution\n",
        "end_time = time.time()\n",
        "print(f\"🕒 Temps total de recherche: {(end_time - start_time)/60:.2f} minutes\")\n",
        "\n",
        "# ✅ Meilleurs hyperparamètres\n",
        "print(\"🏆 Meilleurs hyperparamètres trouvés :\")\n",
        "for param, value in grid_search.best_params_.items():\n",
        "    print(f\"  {param}: {value}\")\n",
        "print(f\"💡 Meilleur score (neg_mean_squared_error): {-grid_search.best_score_:.4f}\")\n",
        "\n",
        "# 📌 Récupérer le meilleur modèle\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "\n",
        "# 📊 Prédictions\n",
        "y_pred_log = best_xgb_model.predict(X_test)\n",
        "y_pred = np.expm1(y_pred_log)\n",
        "y_test_real = np.expm1(y_test_log)\n",
        "\n",
        "# 🧪 Vérif NaN\n",
        "print(\"🔍 Vérification des NaN :\")\n",
        "print(f\"  → y_test_real contient {np.isnan(y_test_real).sum()} NaN\")\n",
        "print(f\"  → y_pred contient {np.isnan(y_pred).sum()} NaN\")\n",
        "\n",
        "# 🧹 Nettoyage\n",
        "mask = ~np.isnan(y_test_real) & ~np.isnan(y_pred)\n",
        "y_test_real_clean = y_test_real[mask]\n",
        "y_pred_clean = y_pred[mask]\n",
        "\n",
        "# 📈 Calcul des métriques\n",
        "rmse = np.sqrt(mean_squared_error(y_test_real_clean, y_pred_clean))\n",
        "r2 = r2_score(y_test_real_clean, y_pred_clean)\n",
        "\n",
        "# 🧾 Résultats\n",
        "print(\"\\n✅ Évaluation sur le jeu de test :\")\n",
        "print(f\"  → RMSE : {rmse:.2f}\")\n",
        "print(f\"  → R²   : {r2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4cabcfe",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vérifier les valeurs réelles\n",
        "print(\"Valeurs de box_office_reels:\")\n",
        "print(box_office_reels.tolist())\n",
        "\n",
        "# Convertir les valeurs réelles avec gestion des séparateurs de milliers\n",
        "def convert_to_float(x):\n",
        "    if pd.isna(x) or x == '-' or x == 'nan':\n",
        "        return np.nan\n",
        "    try:\n",
        "        # Remplacer les espaces et les virgules par rien\n",
        "        if isinstance(x, str):\n",
        "            x = x.replace(' ', '').replace(',', '')\n",
        "        return float(x)\n",
        "    except (ValueError, TypeError):\n",
        "        print(f\"Impossible de convertir '{x}' en nombre\")\n",
        "        return np.nan\n",
        "\n",
        "# Utiliser la fonction de conversion\n",
        "y_real = pd.Series(box_office_reels).apply(convert_to_float)\n",
        "print(\"Valeurs converties:\")\n",
        "print(y_real.tolist())\n",
        "\n",
        "# Appliquer une transformation logarithmique sur les valeurs non-nulles\n",
        "y_real_log = np.log1p(y_real)\n",
        "\n",
        "# Créer un masque pour identifier les films avec des valeurs réelles valides\n",
        "mask_real_values = ~pd.isna(y_real)\n",
        "print(f\"Nombre de films avec box office connu: {mask_real_values.sum()}\")\n",
        "\n",
        "if mask_real_values.sum() > 0:\n",
        "    print(f\"Utilisation de {mask_real_values.sum()} films avec box office connu pour estimer les autres\")\n",
        "    \n",
        "    # Créer un modèle simple\n",
        "    from sklearn.ensemble import RandomForestRegressor\n",
        "    \n",
        "    # Préparer les données pour un modèle simple\n",
        "    X_simple = pd.DataFrame(index=df_test.index)\n",
        "    \n",
        "    # Extraire les features clés\n",
        "    for feature in ['budget', 'duree_minutes', 'mois_sortie', 'annee_sortie']:\n",
        "        if feature in df_test.columns:\n",
        "            X_simple[feature] = pd.to_numeric(df_test[feature], errors='coerce')\n",
        "    \n",
        "    # Ajouter d'autres features si disponibles\n",
        "    if 'trailer_views' in df_test.columns:\n",
        "        X_simple['trailer_views'] = df_test['trailer_views'].apply(\n",
        "            lambda x: float(str(x).replace('vues', '').replace(',', '').replace(' ', '').strip()) \n",
        "            if isinstance(x, str) and 'vues' in x else np.nan\n",
        "        )\n",
        "    \n",
        "    # Remplir les valeurs manquantes\n",
        "    X_simple = X_simple.fillna(X_simple.median())\n",
        "    \n",
        "    # Sélectionner les entrées avec des valeurs réelles\n",
        "    X_train_simple = X_simple[mask_real_values]\n",
        "    y_train_simple = y_real_log[mask_real_values]\n",
        "    \n",
        "    print(\"Features utilisées pour la prédiction:\")\n",
        "    print(X_simple.columns.tolist())\n",
        "    print(\"Statistiques des features:\")\n",
        "    print(X_simple.describe())\n",
        "    \n",
        "    # Entraîner le modèle simple\n",
        "    simple_model = RandomForestRegressor(n_estimators=10, max_depth=3, random_state=42)\n",
        "    simple_model.fit(X_train_simple, y_train_simple)\n",
        "    \n",
        "    # Prédire pour tous les films\n",
        "    y_pred_log_simple = simple_model.predict(X_simple)\n",
        "    y_pred_simple = np.expm1(y_pred_log_simple)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bc39f10",
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, (_, film) in enumerate(df_test.iterrows()):\n",
        "        # Trouver un identifiant pour le film\n",
        "        film_title = None\n",
        "        for title_col in ['titre_allocine', 'titre_clean', 'titre_jpbox', 'film_id']:\n",
        "            if title_col in film and pd.notna(film[title_col]):\n",
        "                film_title = film[title_col]\n",
        "                break\n",
        "        \n",
        "        # Si aucun titre n'est trouvé, utiliser un extrait du synopsis\n",
        "        if film_title is None:\n",
        "            if 'synopsis_x' in film and pd.notna(film['synopsis_x']):\n",
        "                film_title = film['synopsis_x'][:50] + \"...\"\n",
        "            else:\n",
        "                film_title = f\"Film #{i+1}\"\n",
        "        \n",
        "        # Valeur prédite\n",
        "        box_office_predit = y_pred_simple[i]\n",
        "        \n",
        "        # Valeur réelle\n",
        "        box_office_reel = y_real.iloc[i]\n",
        "        \n",
        "        # Formatage pour l'affichage\n",
        "        pred_txt = f\"{box_office_predit:,.0f} entrées\"\n",
        "        real_txt = \"Non disponible\" if pd.isna(box_office_reel) else f\"{box_office_reel:,.0f} entrées\"\n",
        "        \n",
        "        # Affichage\n",
        "        print(f\"- {film_title}\")\n",
        "        print(f\"  - Box office prédit: {pred_txt}\")\n",
        "        print(f\"  - Box office réel: {real_txt}\")\n",
        "        print(\"  --------------------------\")\n",
        "    \n",
        "    # Calculer les métriques d'évaluation sur les films connus\n",
        "valid_indices = mask_real_values\n",
        "if valid_indices.sum() > 0:\n",
        "        from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "        \n",
        "        y_valid_real = y_real[valid_indices]\n",
        "        y_valid_pred = y_pred_simple[valid_indices]\n",
        "        \n",
        "        print(\"\\nÉvaluation des performances:\")\n",
        "        \n",
        "        # R²\n",
        "        r2 = r2_score(y_valid_real, y_valid_pred)\n",
        "        print(f\"R² = {r2:.4f}\")\n",
        "        \n",
        "        # RMSE\n",
        "        rmse = np.sqrt(mean_squared_error(y_valid_real, y_valid_pred))\n",
        "        print(f\"RMSE = {rmse:.2f}\")\n",
        "        \n",
        "        # MAE\n",
        "        mae = mean_absolute_error(y_valid_real, y_valid_pred)\n",
        "        print(f\"MAE = {mae:.2f}\")\n",
        "        \n",
        "        # Erreur relative moyenne\n",
        "        rel_errors = np.abs((y_valid_pred - y_valid_real) / y_valid_real) * 100\n",
        "        print(f\"Erreur relative moyenne: {np.mean(rel_errors):.2f}%\")\n",
        "        print(f\"Erreur médiane: {np.median(rel_errors):.2f}%\")\n",
        "else:\n",
        "        print(\"Pas assez de valeurs réelles pour entraîner un modèle\")"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "fr"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
